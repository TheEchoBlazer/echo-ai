<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta http-equiv="origin-trial" content="">
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Echo-AI — Diagnostics</title>
<style>
  :root{--bg:#0b0f14;--ink:#e8eef9;--muted:#9aa6bb;--line:#213047;--hi:#6ee7ff;--hi2:#8b5cf6}
  *{box-sizing:border-box}
  html,body{height:100%}
  body{margin:0;background:var(--bg);color:var(--ink);font:14px/1.45 system-ui,Segoe UI,Roboto,Arial}
  .wrap{max-width:940px;margin:0 auto;padding:16px}
  h1{margin:0 0 8px 0;font-size:18px}
  .sub{color:var(--muted);font-size:12px;margin-bottom:10px}
  .card{background:#0f1625;border:1px solid var(--line);border-radius:16px;padding:12px;margin:10px 0}
  textarea,input,select,button{border-radius:10px;border:1px solid var(--line);background:#0e1626;color:var(--ink)}
  button{padding:9px 12px;cursor:pointer}
  .action{background:linear-gradient(90deg,var(--hi2),var(--hi));color:#061019;border:none;font-weight:800}
  .row{display:flex;gap:8px;align-items:center;flex-wrap:wrap}
  .status{font-size:12px;color:#a9b5c9}
  .log{font-family:ui-monospace,Consolas,Menlo,monospace;font-size:12px;max-height:220px;overflow:auto;white-space:pre-wrap}
  .chat{min-height:140px;max-height:220px;overflow:auto;border:1px dashed #2a3a5c;border-radius:12px;padding:10px}
  .bubble{background:#141b2c;border:1px solid #213047;border-radius:10px;padding:8px;margin:6px 0}
</style>
</head>
<body>
<div class="wrap">
  <h1>Echo-AI — Diagnostics</h1>
  <div class="sub">This page shows errors instead of hiding them. If it’s still “white screen”, something else is wrong (wrong file path or Pages not updated).</div>

  <div class="card">
    <div class="row">
      <select id="model">
        <option value="Phi-3.5-mini-instruct-q4f16_1-MLC">Phi-3.5-mini (smallest)</option>
        <option value="Qwen2.5-Coder-1.5B-Instruct-q4f16_1-MLC">Qwen2.5-Coder-1.5B</option>
        <option value="Llama-3.1-3B-Instruct-q4f16_1-MLC">Llama-3.1-3B</option>
      </select>
      <button id="load" class="action">Load Model</button>
      <button id="ping">Check WebLLM</button>
    </div>
    <div id="status" class="status">Status: page rendered ✔︎</div>
  </div>

  <div class="card">
    <div class="row">
      <textarea id="in" placeholder="Type a prompt… (e.g., Skript /dupe with cooldown & permission)"></textarea>
      <button id="send" class="action">Send</button>
    </div>
    <div id="chat" class="chat"></div>
  </div>

  <div class="card">
    <b>Debug log</b>
    <div id="log" class="log"></div>
  </div>
</div>

<script>
/* ---------- minimal logger that never crashes ---------- */
const $ = s => document.querySelector(s);
const logEl = $("#log"), statusEl=$("#status"), chat=$("#chat");
function log(...a){ const line=a.map(x=> typeof x==='string'?x:JSON.stringify(x)).join(' '); console.log("[Echo-AI]",...a); const div=document.createElement('div'); div.textContent=line; logEl.appendChild(div); logEl.scrollTop=logEl.scrollHeight; }
function status(t){ statusEl.textContent = "Status: " + t; log(t); }
window.addEventListener("error", e=>{ log("window.error:", e.message); status("ERROR: "+e.message); });
window.addEventListener("unhandledrejection", e=>{ log("unhandledrejection:", e.reason?.message||e.reason); status("Promise ERROR: "+(e.reason?.message||e.reason)); });

/* ---------- step 1: load WebLLM with visible progress ---------- */
(async function loadWebLLM(){
  async function inject(src){
    return new Promise(res=>{
      const s=document.createElement("script");
      s.src=src; s.async=true;
      s.onload=()=>{ log("loaded:",src); res(true); };
      s.onerror=()=>{ log("failed:",src); res(false); };
      document.head.appendChild(s);
    });
  }
  status("loading WebLLM…");
  for (const url of [
    "https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.55/dist/web-llm.umd.min.js",
    "https://unpkg.com/@mlc-ai/web-llm@0.2.55/dist/web-llm.umd.min.js"
  ]) {
    if (await inject(url) && window.webllm) break;
  }
  if (window.webllm) {
    status("WebLLM ready. Click Load Model.");
  } else {
    status("Couldn’t load WebLLM (CDN blocked or offline). Open this Pages URL directly (not embedded), or try another browser.");
  }
})();

/* ---------- UI + safe chat calls ---------- */
let engine=null, lastReply="";
const sys=[{role:"system",content:
`You are a focused coding helper for Minecraft Skript (Minehut/Purpur/1.21.x, SkBee) and Gorilla Tag/Unity 2021.3.21f1 (Photon PUN 2, PlayFab).
Return concise, copy-pasteable code blocks in triple backticks. Avoid deprecated Skript syntaxes.`}];

$("#ping").addEventListener("click", ()=>{
  if (window.webllm) status("webllm object exists ✔︎");
  else status("webllm is undefined ✖︎ (CDN blocked)");
});

$("#load").addEventListener("click", async ()=>{
  try{
    if(!window.webllm) { status("WebLLM missing — can’t load model."); return; }
    const { CreateMLCEngine, prebuiltAppConfig } = window.webllm;
    const modelId = $("#model").value;
    status("Loading "+modelId+" …");
    engine = await CreateMLCEngine(modelId,
      { appConfig: prebuiltAppConfig, useWebWorker:false, gpu:true },
      (p)=> status(`${p.text} ${Math.round(p.progress*100)}%`)
    );
    status("Loaded "+modelId+" ✔︎  Type and press Send.");
  }catch(e){ log(e); status("Load error: "+e.message); }
});

function add(role, text){
  const b=document.createElement("div");
  b.className="bubble"; b.textContent = (role==="user" ? "You: " : "Echo-AI: ") + text;
  chat.appendChild(b); chat.scrollTop=chat.scrollHeight;
  return b;
}

async function runLocal(messages){
  // try modern API
  try{
    if (engine?.chat?.completions?.create){
      const out = await engine.chat.completions.create({
        messages, temperature:0.2, max_tokens:900, max_new_tokens:900, stream:false
      });
      return out?.choices?.[0]?.message?.content ?? null;
    }
  }catch(e){ log("new API failed →", e.message); }
  // fallback to legacy
  if (typeof engine?.generate === "function"){
    const prompt = messages.map(m=>`${m.role.toUpperCase()}: ${m.content}`).join("\n")+"\nASSISTANT:";
    const out = await engine.generate(prompt, { temperature:0.2, max_tokens:900 });
    return out?.output_text || (typeof out==="string" ? out : null);
  }
  throw new Error("No compatible WebLLM method found.");
}

$("#send").addEventListener("click", async ()=>{
  const t = $("#in").value.trim();
  if (!t){ status("Type something first."); return; }
  if (!engine){ status("Load a model first."); return; }
  $("#in").value = ""; add("user", t); const thinking = add("assistant","…thinking…");
  try{
    const reply = await runLocal(sys.concat({role:"user",content:t}));
    lastReply = reply || "(no text returned)";
    thinking.textContent = "Echo-AI: " + lastReply;
    status("Done.");
  }catch(e){
    log("send error:", e); thinking.textContent = "Echo-AI: [Error] " + e.message; status("Generation error.");
  }
});
</script>
</body>
</html>
